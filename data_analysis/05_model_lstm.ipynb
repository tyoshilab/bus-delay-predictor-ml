{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bfc4be",
   "metadata": {},
   "source": [
    "# 05. Model LSTM\n",
    "LSTM model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174693f",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, r2_score\nimport utils\nimport os\n\n# Load Processed Data\nprocessed_file = 'data/processed_data/processed_trip_data.csv'\nif os.path.exists(processed_file):\n    df_process = pd.read_csv(processed_file)\n    df_process['start_date'] = df_process['start_date'].astype(str)\n    print(f\"Loaded processed data from {processed_file}\")\n\n    # Split\n    unique_dates = sorted(df_process['start_date'].unique())\n    split_idx = int(len(unique_dates) * 0.8)\n    train_dates = unique_dates[:split_idx]\n    test_dates = unique_dates[split_idx:]\n\n    df_train = df_process[df_process['start_date'].isin(train_dates)].copy()\n    df_test = df_process[df_process['start_date'].isin(test_dates)].copy()\nelse:\n    print(f\"File not found: {processed_file}. Please run 02_process_data.ipynb first.\")\n    df_process = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sequences\n",
    "if df_process is not None:\n",
    "    n_past_trips = 5\n",
    "    stops_dict = {}\n",
    "    for rd_key in df_process['route_direction_key'].unique():\n",
    "        rd_df = df_process[df_process['route_direction_key'] == rd_key]\n",
    "        stops_dict[rd_key] = sorted(rd_df['stop_sequence'].unique())\n",
    "\n",
    "    X_delays_train, X_features_train, X_agg_train, y_train, _, _, n_stops = utils.create_trip_based_sequences_multi_route(\n",
    "        df_train, n_past_trips, stops_dict=stops_dict\n",
    "    )\n",
    "    X_delays_test, X_features_test, X_agg_test, y_test, _, _, _ = utils.create_trip_based_sequences_multi_route(\n",
    "        df_test, n_past_trips, stops_dict=stops_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "if df_process is not None:\n",
    "    delay_scaler = StandardScaler()\n",
    "    X_delays_train_scaled = delay_scaler.fit_transform(X_delays_train.reshape(-1, n_stops)).reshape(X_delays_train.shape)\n",
    "    X_delays_test_scaled = delay_scaler.transform(X_delays_test.reshape(-1, n_stops)).reshape(X_delays_test.shape)\n",
    "\n",
    "    y_train_scaled = delay_scaler.transform(y_train)\n",
    "    y_test_scaled = delay_scaler.transform(y_test)\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_combined_train = np.concatenate([X_features_train, X_agg_train], axis=1)\n",
    "    X_combined_test = np.concatenate([X_features_test, X_agg_test], axis=1)\n",
    "\n",
    "    X_combined_train_scaled = feature_scaler.fit_transform(X_combined_train)\n",
    "    X_combined_test_scaled = feature_scaler.transform(X_combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b748c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "def build_trip_lstm_model(n_past_trips, n_stops, n_features):\n",
    "    delay_input = Input(shape=(n_past_trips, n_stops), name='delay_input')\n",
    "    x = LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001))(delay_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=False, kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    feature_input = Input(shape=(n_features,), name='feature_input')\n",
    "    f = Dense(32, activation='relu')(feature_input)\n",
    "    f = Dropout(0.2)(f)\n",
    "    f = Dense(16, activation='relu')(f)\n",
    "\n",
    "    combined = Concatenate()([x, f])\n",
    "    combined = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(combined)\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Dropout(0.3)(combined)\n",
    "    combined = Dense(32, activation='relu')(combined)\n",
    "\n",
    "    output = Dense(n_stops, activation='linear')(combined)\n",
    "\n",
    "    model = Model(inputs=[delay_input, feature_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "if df_process is not None:\n",
    "    n_features = X_combined_train.shape[1]\n",
    "    model = build_trip_lstm_model(n_past_trips, n_stops, n_features)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "if df_process is not None:\n",
    "    history = model.fit(\n",
    "        [X_delays_train_scaled, X_combined_train_scaled],\n",
    "        y_train_scaled,\n",
    "        validation_split=0.2,\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred_scaled = model.predict([X_delays_test_scaled, X_combined_test_scaled])\n",
    "    y_pred = delay_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    mae_lstm = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
    "    r2_lstm = r2_score(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "    print(f\"LSTM MAE: {mae_lstm:.2f}, R2: {r2_lstm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}