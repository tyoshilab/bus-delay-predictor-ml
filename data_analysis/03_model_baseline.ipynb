{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2371d996",
   "metadata": {},
   "source": [
    "# 03. Model Baseline\n",
    "Baseline models implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import utils\n",
    "import os\n",
    "\n",
    "# Load Processed Data\n",
    "processed_file = 'data/processed_data/processed_trip_data.csv'\n",
    "if os.path.exists(processed_file):\n",
    "    df_process = pd.read_csv(processed_file)\n",
    "    df_process['start_date'] = df_process['start_date'].astype(str)\n",
    "    print(f\"Loaded processed data from {processed_file}\")\n",
    "    \n",
    "    # Split\n",
    "    unique_dates = sorted(df_process['start_date'].unique())\n",
    "    split_idx = int(len(unique_dates) * 0.8)\n",
    "    train_dates = unique_dates[:split_idx]\n",
    "    test_dates = unique_dates[split_idx:]\n",
    "\n",
    "    df_train = df_process[df_process['start_date'].isin(train_dates)].copy()\n",
    "    df_test = df_process[df_process['start_date'].isin(test_dates)].copy()\n",
    "else:\n",
    "    print(f\"File not found: {processed_file}. Please run 02_process_data.ipynb first.\")\n",
    "    df_process = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc32ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trip_based_sequences_multi_route(df, n_past_trips=5, stops_dict=None):\n",
    "    all_X_delays = []\n",
    "    all_X_features = []\n",
    "    all_X_agg = []  # 集約特徴量\n",
    "    all_y = []\n",
    "    all_meta = []\n",
    "\n",
    "    feature_cols = [\n",
    "       'hour_of_day'\n",
    "       , 'arrival_delay_agg'\n",
    "       , 'day_of_week'\n",
    "       , 'time_of_day'\n",
    "       , 'time_sin'\n",
    "       , 'time_cos'\n",
    "       , 'is_weekend'\n",
    "       , 'is_rush_hour'\n",
    "       , 'has_active_alert'\n",
    "       , 'has_detour'\n",
    "       , 'has_police_alert'\n",
    "    ]\n",
    "\n",
    "    # route_direction_keyごとに処理\n",
    "    rd_keys = sorted(df['route_direction_key'].unique())\n",
    "    print(f\"Processing {len(rd_keys)} route-direction combinations\")\n",
    "\n",
    "    if stops_dict is None:\n",
    "        stops_dict = {}\n",
    "        for rd_key in rd_keys:\n",
    "            rd_df = df[df['route_direction_key'] == rd_key]\n",
    "            stops_dict[rd_key] = sorted(rd_df['stop_sequence'].unique())\n",
    "\n",
    "    # 全route-directionで共通のstops数を使用（パディング用）\n",
    "    max_stops = max(len(stops) for stops in stops_dict.values())\n",
    "    print(f\"Max stops across all route-directions: {max_stops}\")\n",
    "\n",
    "    for rd_key in rd_keys:\n",
    "        rd_df = df[df['route_direction_key'] == rd_key].copy()\n",
    "        stops = stops_dict.get(rd_key, sorted(rd_df['stop_sequence'].unique()))\n",
    "        n_stops = len(stops)\n",
    "\n",
    "        # Trip単位で時間順にソート\n",
    "        trip_order = rd_df.groupby('trip_key')['scheduled_arrival_time'].min().sort_values().index.tolist()\n",
    "\n",
    "        if len(trip_order) <= n_past_trips:\n",
    "            # print(f\"  {rd_key}: Not enough trips ({len(trip_order)}), skipping\")\n",
    "            continue\n",
    "\n",
    "        # 1. 遅延パターン (trip x stop)\n",
    "        delay_pivot = rd_df.pivot_table(\n",
    "            index='trip_key', columns='stop_sequence',\n",
    "            values='arrival_delay_agg', aggfunc='first'\n",
    "        )\n",
    "        delay_pivot = delay_pivot.reindex(index=trip_order, columns=stops).ffill(axis=1).fillna(0)\n",
    "\n",
    "        # stopsを共通サイズにパディング\n",
    "        if n_stops < max_stops:\n",
    "            padding = np.zeros((len(delay_pivot), max_stops - n_stops))\n",
    "            delay_values = np.concatenate([delay_pivot.values, padding], axis=1)\n",
    "        else:\n",
    "            delay_values = delay_pivot.values\n",
    "\n",
    "        # 2. 時間・天候・アラート特徴量 + route_direction_encoded\n",
    "        trip_features = rd_df.groupby('trip_key')[feature_cols + ['route_direction_encoded']].first()\n",
    "        trip_features = trip_features.reindex(index=trip_order).fillna(0)\n",
    "\n",
    "        # シーケンス作成\n",
    "        for i in range(n_past_trips, len(trip_order)):\n",
    "            # 過去N便の遅延パターン（同じroute+directionのみ）\n",
    "            past_delays = delay_values[i-n_past_trips:i]  # (n_past_trips, max_stops)\n",
    "\n",
    "            # 予測対象便の特徴量\n",
    "            target_features = trip_features.iloc[i].values  # (n_features,)\n",
    "\n",
    "            # ★ 集約特徴量 ★\n",
    "            past_mean = past_delays.mean()\n",
    "            past_std = past_delays.std()\n",
    "            past_trend = past_delays[-1].mean() - past_delays[0].mean()\n",
    "            past_max = past_delays.max()\n",
    "            agg_features = np.array([past_mean, past_std, past_trend, past_max])\n",
    "\n",
    "            # 予測対象の遅延\n",
    "            target_delay = delay_values[i]  # (max_stops,)\n",
    "\n",
    "            all_X_delays.append(past_delays)\n",
    "            all_X_features.append(target_features)\n",
    "            all_X_agg.append(agg_features)\n",
    "            all_y.append(target_delay)\n",
    "            all_meta.append(trip_order[i])\n",
    "\n",
    "    X_delays = np.array(all_X_delays)  # (N, n_past_trips, max_stops)\n",
    "    X_features = np.array(all_X_features)  # (N, n_features)\n",
    "    X_agg = np.array(all_X_agg)  # (N, 4)\n",
    "    y = np.array(all_y)  # (N, max_stops)\n",
    "\n",
    "    print(f\"\\nTotal X_delays shape: {X_delays.shape}\")\n",
    "    print(f\"Total X_features shape: {X_features.shape}\")\n",
    "    print(f\"Total X_agg shape: {X_agg.shape}\")\n",
    "    print(f\"Total y shape: {y.shape}\")\n",
    "\n",
    "    return X_delays, X_features, X_agg, y, all_meta, stops_dict, max_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sequences\n",
    "if df_process is not None:\n",
    "    n_past_trips = 5\n",
    "    stops_dict = {}\n",
    "    for rd_key in df_process['route_direction_key'].unique():\n",
    "        rd_df = df_process[df_process['route_direction_key'] == rd_key]\n",
    "        stops_dict[rd_key] = sorted(rd_df['stop_sequence'].unique())\n",
    "\n",
    "    print(\"Creating sequences...\")\n",
    "    X_delays_test, X_features_test, X_agg_test, y_test, meta_test, _, _ = create_trip_based_sequences_multi_route(\n",
    "        df_test, n_past_trips, stops_dict=stops_dict\n",
    "    )\n",
    "    # We need train sequences for Baseline 3 (history average)\n",
    "    X_delays_train, _, _, _, _, _, _ = create_trip_based_sequences_multi_route(\n",
    "        df_train, n_past_trips, stops_dict=stops_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: Last Trip Delay\n",
    "if df_process is not None:\n",
    "    y_pred_baseline1 = X_delays_test[:, -1, :]\n",
    "    mae_bl1 = mean_absolute_error(y_test.flatten(), y_pred_baseline1.flatten())\n",
    "    r2_bl1 = r2_score(y_test.flatten(), y_pred_baseline1.flatten())\n",
    "\n",
    "    print(f\"Baseline 1 (Last Trip) MAE: {mae_bl1:.2f}, R2: {r2_bl1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 2: Mean of Past N Trips\n",
    "if df_process is not None:\n",
    "    y_pred_baseline2 = X_delays_test.mean(axis=1)\n",
    "    mae_bl2 = mean_absolute_error(y_test.flatten(), y_pred_baseline2.flatten())\n",
    "    r2_bl2 = r2_score(y_test.flatten(), y_pred_baseline2.flatten())\n",
    "\n",
    "    print(f\"Baseline 2 (Mean Past N) MAE: {mae_bl2:.2f}, R2: {r2_bl2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
